# Assessment Tools Guide: AI and Mental Health Study

## Overview
This guide provides detailed information about the standardized assessment tools used in the AI and Mental Health Study, including their psychometric properties, administration procedures, and scoring methods.

## Primary Assessment Measures

### 1. Automatic Thoughts Questionnaire (ATQ)

#### Purpose
The ATQ is designed to measure the frequency of negative automatic thoughts, which are a key component of cognitive-behavioral theory and are associated with depression and anxiety.

#### Description
- **Developer**: Hollon & Kendall (1980)
- **Items**: 30 statements reflecting negative automatic thoughts
- **Response Format**: 5-point Likert scale (1 = Not at all to 5 = All the time)
- **Administration Time**: 10-15 minutes
- **Scoring**: Sum of all item scores (range: 30-150)

#### Psychometric Properties
- **Reliability**: Internal consistency α = 0.96
- **Validity**: Strong correlations with depression and anxiety measures
- **Norms**: College student population available
- **Clinical Cutoffs**: 
  - Normal: 30-79
  - Mild: 80-99
  - Moderate: 100-119
  - Severe: 120-150

#### Administration Instructions
1. Explain the purpose of the questionnaire
2. Emphasize honest responses based on current thoughts
3. Allow sufficient time for completion
4. Answer any questions about specific items
5. Collect completed forms immediately

#### Scoring Guidelines
- **Total Score**: Sum all 30 items
- **Subscale Scores**: Can be calculated for specific thought categories
- **Missing Data**: If >10% items missing, consider invalid
- **Reverse Scoring**: None required

### 2. Cognitive Emotion Regulation Questionnaire (CERQ)

#### Purpose
The CERQ assesses individual differences in the use of cognitive emotion regulation strategies when confronted with negative life events.

#### Description
- **Developer**: Garnefski, Kraaij, & Spinhoven (2001)
- **Items**: 36 items across 9 subscales
- **Response Format**: 5-point Likert scale (1 = Almost never to 5 = Almost always)
- **Administration Time**: 15-20 minutes
- **Scoring**: Subscale scores and total adaptive/maladaptive scores

#### Subscales
1. **Self-blame**: Blaming yourself for what happened
2. **Acceptance**: Accepting the situation and resigning yourself
3. **Rumination**: Thinking about the feelings and thoughts associated with the negative event
4. **Positive refocusing**: Thinking about pleasant and joyful issues
5. **Refocus on planning**: Thinking about what steps to take and how to handle the negative event
6. **Positive reappraisal**: Creating a positive meaning to the event in terms of personal growth
7. **Putting into perspective**: Making light of the situation or emphasizing the relativity
8. **Catastrophizing**: Emphasizing the terror of what you have experienced
9. **Other-blame**: Blaming another person or thing for what happened

#### Psychometric Properties
- **Reliability**: Internal consistency α = 0.75-0.87 across subscales
- **Validity**: Good construct validity and discriminant validity
- **Norms**: Available for various populations including college students
- **Adaptive vs. Maladaptive**: Subscales categorized based on research findings

#### Administration Instructions
1. Provide clear instructions about the reference period
2. Emphasize thinking about recent negative events
3. Ensure understanding of each subscale concept
4. Allow adequate time for thoughtful responses
5. Monitor for comprehension difficulties

#### Scoring Guidelines
- **Subscale Scores**: Mean of items within each subscale
- **Adaptive Strategies**: Positive refocusing, refocus on planning, positive reappraisal, putting into perspective, acceptance
- **Maladaptive Strategies**: Self-blame, rumination, catastrophizing, other-blame
- **Total Adaptive Score**: Mean of adaptive subscales
- **Total Maladaptive Score**: Mean of maladaptive subscales

### 3. Perceived Stress Scale (PSS)

#### Purpose
The PSS measures the degree to which situations in one's life are appraised as stressful, focusing on the subjective experience of stress.

#### Description
- **Developer**: Cohen, Kamarck, & Mermelstein (1983)
- **Items**: 10 items (PSS-10 version used in this study)
- **Response Format**: 5-point Likert scale (0 = Never to 4 = Very often)
- **Administration Time**: 5-10 minutes
- **Scoring**: Sum of all items (range: 0-40)

#### Psychometric Properties
- **Reliability**: Internal consistency α = 0.78-0.91
- **Validity**: Strong correlations with health outcomes and stress biomarkers
- **Norms**: Extensive normative data available
- **Clinical Cutoffs**:
  - Low stress: 0-13
  - Moderate stress: 14-26
  - High stress: 27-40

#### Administration Instructions
1. Emphasize the subjective nature of stress perception
2. Clarify the reference period (past month)
3. Explain that there are no right or wrong answers
4. Encourage honest responses based on personal experience
5. Address any confusion about specific items

#### Scoring Guidelines
- **Total Score**: Sum of all 10 items
- **Reverse Scoring**: Items 4, 5, 7, and 8 are reverse-scored
- **Missing Data**: If >2 items missing, consider invalid
- **Interpretation**: Higher scores indicate greater perceived stress

### 4. AJ SRS (Student Reflection Scale)

#### Purpose
The AJ SRS measures students' capacity for reflective thinking, which is important for learning and personal development.

#### Description
- **Developer**: [Study-specific adaptation]
- **Items**: Custom scale developed for this study
- **Response Format**: Likert scale (specific format to be determined)
- **Administration Time**: 5-10 minutes
- **Scoring**: Custom scoring algorithm

#### Psychometric Properties
- **Reliability**: To be established through pilot testing
- **Validity**: To be validated against other reflection measures
- **Norms**: To be developed for college student population
- **Clinical Cutoffs**: To be determined based on normative data

#### Administration Instructions
1. Explain the concept of reflective thinking
2. Provide examples of reflective vs. non-reflective responses
3. Emphasize the importance of honest self-assessment
4. Allow time for thoughtful consideration of responses
5. Monitor for understanding and engagement

#### Scoring Guidelines
- **Scoring Method**: To be determined based on scale development
- **Missing Data**: Protocol to be established
- **Interpretation**: Guidelines to be developed

## Secondary Assessment Measures

### Session Feedback Questionnaire

#### Purpose
To assess participant satisfaction, engagement, and experience with the AI conversation sessions.

#### Description
- **Developer**: Study-specific measure
- **Items**: Mix of quantitative and qualitative items
- **Response Format**: Various formats including Likert scales and open-ended questions
- **Administration Time**: 5-10 minutes
- **Scoring**: Quantitative items scored numerically; qualitative items analyzed thematically

#### Content Areas
1. **Session Satisfaction**: Overall experience and helpfulness
2. **AI Interaction Quality**: Comfort level and effectiveness
3. **Emotional Impact**: Changes in mood and emotional state
4. **Cognitive Engagement**: Level of reflection and insight
5. **Technical Experience**: Ease of use and technical issues
6. **Suggestions for Improvement**: Open-ended feedback

#### Administration Instructions
1. Emphasize the importance of honest feedback
2. Explain that feedback will help improve the intervention
3. Encourage detailed responses to open-ended questions
4. Assure confidentiality of responses
5. Collect immediately after each session

### Demographic and Background Information

#### Purpose
To collect relevant participant characteristics for analysis and interpretation.

#### Content Areas
1. **Demographics**: Age, gender, academic year, major
2. **Mental Health History**: Previous therapy, current medications
3. **Technology Experience**: Comfort with AI and digital tools
4. **Academic Information**: GPA, course load, stress levels
5. **Social Support**: Family and peer support networks

## Administration Protocol

### Standardized Procedures
1. **Consent Process**: Informed consent before any assessments
2. **Instructions**: Standardized instructions for each measure
3. **Timing**: Consistent administration timing across sessions
4. **Environment**: Quiet, private setting for all assessments
5. **Support**: Available assistance for questions or concerns

### Quality Assurance
1. **Training**: Research staff trained in proper administration
2. **Monitoring**: Regular checks for protocol adherence
3. **Documentation**: Complete records of administration procedures
4. **Feedback**: Participant feedback on assessment experience
5. **Revision**: Ongoing refinement based on participant input

### Data Management
1. **Collection**: Secure, immediate collection of completed forms
2. **Storage**: Encrypted, password-protected digital storage
3. **Backup**: Regular backup of all assessment data
4. **Access**: Limited access to raw assessment data
5. **Retention**: IRB-approved data retention schedule

## Scoring and Analysis

### Automated Scoring
- **Digital Forms**: Use of digital assessment platforms where possible
- **Immediate Scoring**: Real-time calculation of scores
- **Error Checking**: Automated validation of response patterns
- **Data Export**: Secure export to analysis software

### Manual Scoring
- **Double Scoring**: Independent scoring by two researchers
- **Discrepancy Resolution**: Protocol for resolving scoring differences
- **Quality Checks**: Regular audits of scoring accuracy
- **Documentation**: Complete records of scoring procedures

### Data Integration
- **Cross-Platform Integration**: Combining data from multiple sources
- **Longitudinal Tracking**: Following individual participants across sessions
- **Missing Data Management**: Protocols for handling incomplete data
- **Statistical Preparation**: Data cleaning and preparation for analysis

## Ethical Considerations

### Privacy Protection
- **De-identification**: Removal of personal identifiers from data
- **Confidentiality**: Secure handling of sensitive information
- **Consent**: Clear explanation of data use and storage
- **Rights**: Participant rights to withdraw and access data

### Cultural Sensitivity
- **Language**: Clear, accessible language in all measures
- **Cultural Relevance**: Consideration of cultural factors in interpretation
- **Accessibility**: Accommodations for diverse abilities and needs
- **Respect**: Respectful treatment of all participants

### Professional Standards
- **Training**: Proper training in assessment administration
- **Supervision**: Regular supervision and consultation
- **Continuing Education**: Ongoing professional development
- **Ethics**: Adherence to professional ethical guidelines

---

*This guide ensures consistent, professional administration of all assessment tools in the AI and Mental Health Study, maintaining the highest standards of research quality and participant care.*
